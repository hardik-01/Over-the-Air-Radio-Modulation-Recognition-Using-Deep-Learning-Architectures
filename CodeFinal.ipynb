{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version is  2.10.1\n",
      "Keras version      :  2.10.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow import Tensor\n",
    "print(\"Tensorflow version is \", tf.__version__)\n",
    "print('Keras version      : ',keras.__version__)\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import h5py as h5\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import random\n",
    "import time\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Input, Conv2DTranspose, Concatenate, BatchNormalization, UpSampling2D\n",
    "from tensorflow.keras.layers import  Dropout, Activation, GlobalAveragePooling1D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam, SGD, Adadelta\n",
    "from tensorflow.keras.layers import Reshape, Dense, Flatten, Add\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, History\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from random import shuffle\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from progressbar import ProgressBar\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "data_file = \"GOLD_XYZ_OSC.0001_1024.hdf5 \"\n",
    "file_handle = h5.File(data_file,'r+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2555904, 1024, 2)\n",
      "(2555904, 24)\n",
      "(2555904, 1)\n"
     ]
    }
   ],
   "source": [
    "myData = file_handle['X'][:]  #1024x2 samples \n",
    "myMods = file_handle['Y'][:]  #mods \n",
    "mySNRs = file_handle['Z'][:]  #snrs  \n",
    "\n",
    "print(np.shape(myData))\n",
    "print(np.shape(myMods))\n",
    "print(np.shape(mySNRs))\n",
    "file_handle.close()\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-20, -18, -16, -14, -12, -10, -8, -6, -4, -2, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30]\n"
     ]
    }
   ],
   "source": [
    "snrs = list(np.unique(mySNRs.T[0]))  \n",
    "print(snrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mods = [\n",
    "    'OOK',      '4ASK',      '8ASK',      'BPSK',   'QPSK',    '8PSK',\n",
    "    '16PSK',    '32PSK',     '16APSK',    '32APSK', '64APSK',  '128APSK',\n",
    "    '16QAM',    '32QAM',     '64QAM',     '128QAM', '256QAM',  \n",
    "    'AM-SSB-WC','AM-SSB-SC', 'AM-DSB-WC', 'AM-DSB-SC', 'FM', 'GMSK','OQPSK']\n",
    "\n",
    "num_classes = np.shape(mods)[0]\n",
    "print(\"The number of classes is \", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Printing one example from each modulation class\n",
    "\n",
    "#turn off warning about more than 10 figures plotted\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "\n",
    "def my_range(start, end, step):\n",
    "    while start <= end:\n",
    "        yield start\n",
    "        start += step\n",
    "\n",
    "size = np.size(myData, axis = 0)\n",
    "step = size//24\n",
    "# print(size)\n",
    "# for x in my_range(100000, (size-1), step):\n",
    "#   plt.figure()\n",
    "#   plt.suptitle( mods[np.argmax(myMods[x])])\n",
    "#   plt.plot(myData[x,:,0])\n",
    "#   plt.plot(myData[x,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"The number of classes is \", num_classes)\n",
    "# print(\"myData \" , np.shape(myData))\n",
    "# print(\"myMods \" , np.shape(myMods))\n",
    "# print(\"mySNRs \" , np.shape(mySNRs))\n",
    "# print (\"Max value of the data set = \", np.max(myData))\n",
    "# print (\"Min value of the data set = \", np.min(myData))\n",
    "# print (\"Mean value of the data set = \", np.mean(myData))\n",
    "# print (\"Standard Deviation of the data set \", np.std(myData) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len = (myData.shape[0])\n",
    "limit = 5\n",
    "Max = np.zeros(len)\n",
    "Min = np.zeros(len)\n",
    "for i in range(0,len):\n",
    "  Max[i] = (np.max(myData[i,:,0]))\n",
    "  Min[i] = (np.min(myData[i,:,0]))\n",
    "  if(Max[i] > limit or Min[i] < -limit):\n",
    "   print (\"index =\", i, mods[np.argmax(myMods[i])])\n",
    "plt.figure() \n",
    "plt.plot(Max)\n",
    "plt.plot(Min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Skip this entire panel if you want to leave AM-SSB-WC and AM-SSB-SC modulations in the data set\n",
    "myData = np.concatenate((myData[0:1810432], myData[2023424:2555904]),axis=0)\n",
    "mySNRs = np.concatenate((mySNRs[0:1810432], mySNRs[2023424:2555904]),axis=0)\n",
    "myMods = np.concatenate((myMods[0:1810432], myMods[2023424:2555904]),axis=0)\n",
    "\n",
    "#re-onehot encode myMods to 22 from 24\n",
    "length = (np.size(myMods, axis=0))\n",
    "temp = np.concatenate((myMods[:,0:17],myMods[:,19:24]), axis=1)\n",
    "myMods = temp\n",
    "\n",
    "mods = [\n",
    "    'OOK',      '4ASK',      '8ASK',      'BPSK',   'QPSK',    '8PSK',\n",
    "    '16PSK',    '32PSK',     '16APSK',    '32APSK', '64APSK',  '128APSK',\n",
    "    '16QAM',    '32QAM',     '64QAM',     '128QAM', '256QAM',  \n",
    "    'AM-DSB-WC', 'AM-DSB-SC', 'FM', 'GMSK','OQPSK']\n",
    "\n",
    "num_classes = np.shape(mods)[0]\n",
    "print(\"The number of classes is \", num_classes)\n",
    "\n",
    "\n",
    "print(np.shape(myData))\n",
    "print(np.shape(mySNRs))\n",
    "print(np.shape(myMods))\n",
    "\n",
    "\n",
    "print (\"Max value of the data set = \", np.max(myData))\n",
    "print (\"Min value of the data set = \", np.min(myData))\n",
    "print (\"Mean value of the data set = \", np.mean(myData))\n",
    "print (\"Standard Deviation of the data set \", np.std(myData) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.suptitle(\"SNR Distribution\")\n",
    "plt.hist(mySNRs, bins = [-20, -18, -16, -14, -12, -10, -8, -6, -4, -2, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32]) \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myData = myData.reshape(myData.shape[0], 1024, 1, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train ,X_test ,Y_train ,Y_test, Z_train, Z_test =train_test_split(myData, myMods, mySNRs, test_size=0.2, random_state=0)\n",
    "print (np.shape(X_test))\n",
    "print (np.shape(Y_test))\n",
    "print (np.shape(Z_test))\n",
    "print (np.shape(X_train))\n",
    "print (np.shape(Y_train))\n",
    "print (np.shape(Z_train))\n",
    "del myData, myMods, mySNRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shp = list(X_train.shape[1:])\n",
    "print(\"Dataset Shape={0} CNN Model Input layer={1}\".format(X_train.shape, input_shp))\n",
    "classes = mods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_block(input_data, filters, conv_size):\n",
    "  x = Conv2D(filters, 1, activation=None, padding='same')(input_data)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = Conv2D(filters, conv_size, activation=None, padding='same')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = Conv2D(filters, conv_size, activation=None, padding='same')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Add()([x, input_data])\n",
    "  x = Activation('relu')(x)\n",
    "    \n",
    "  y = Conv2D(filters, conv_size, activation=None, padding='same')(x)\n",
    "  y = BatchNormalization()(y)\n",
    "  y = Activation('relu')(y)\n",
    "  y = Conv2D(filters, conv_size, activation=None, padding='same')(y)\n",
    "  y = BatchNormalization()(y)    \n",
    "  y = Add()([y, x])\n",
    "  y = Activation('relu')(y)\n",
    "  \n",
    "  z = MaxPooling2D(2, strides = (2,1), padding = 'same') (y)\n",
    "  return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using 6 blocks will give small accuracy improvment with 5% decrease in performance\n",
    "#num_resnet_blocks = 6\n",
    "\n",
    "num_resnet_blocks = 6\n",
    "num_filters = 32\n",
    "kernel_size = 5,1\n",
    "\n",
    "rf_input = Input(shape=input_shp, name = 'rf_input')\n",
    "\n",
    "x = Conv2D(num_filters, (kernel_size), activation=None, padding='same')(rf_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "for i in range(num_resnet_blocks):\n",
    "    x = resnet_block(x, num_filters, (kernel_size))\n",
    "\n",
    "x = Conv2D(num_filters, (kernel_size), activation=None, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "# use if number of resnet blocks = 6\n",
    "x = Reshape((4,4,num_filters), input_shape = (16,1,num_filters)) (x)\n",
    "\n",
    "# use if number of resent blocks = 4\n",
    "# x = Reshape((8,8,num_filters), input_shape = (32,1,num_filters)) (x)\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "dense_1 = Dense(256, activation='relu')(x)\n",
    "dropout_1 = Dropout(0.5)(dense_1)\n",
    "dense_2 = Dense(128, activation='relu')(dropout_1)\n",
    "dropout_2 = Dropout(0.5)(dense_2)\n",
    "dense_3 = Dense(num_classes)(dropout_2)          \n",
    "softmax = Activation('softmax', name = 'softmax')(dense_3)\n",
    "\n",
    "optimizer= Adam(learning_rate=0.00050)\n",
    "model = keras.Model(rf_input, softmax)\n",
    "model.compile(loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CODE FOR CLDNN ( TO USE THIS REMOVE CNN CODE GIVEN ABOVE AND ALSO DONT USE DATA GENERATOR FUNCTIN BELOW TO LOAD THE DATASET FROM CPU TO GPU)\n",
    "\n",
    "# from keras.layers import Input, ConvLSTM2D, BatchNormalization, Activation, GlobalAveragePooling2D, Dense, Dropout, Softmax, Reshape\n",
    "# from keras.models import Model\n",
    "# from keras.optimizers import Adam\n",
    "\n",
    "# num_filters = 32\n",
    "# kernel_size = (5, 1)\n",
    "\n",
    "# rf_input = Input(shape=input_shp, name='rf_input')\n",
    "\n",
    "# # reshape input to add the time dimension\n",
    "# x = Reshape((-1, input_shp[0], input_shp[1], 1))(rf_input)\n",
    "\n",
    "# x = ConvLSTM2D(filters=num_filters, kernel_size=kernel_size, padding='same', return_sequences=True)(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Activation('relu')(x)\n",
    "\n",
    "# x = ConvLSTM2D(filters=num_filters, kernel_size=kernel_size, padding='same', return_sequences=True)(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Activation('relu')(x)\n",
    "\n",
    "# x = ConvLSTM2D(filters=num_filters, kernel_size=kernel_size, padding='same', return_sequences=True)(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Activation('relu')(x)\n",
    "\n",
    "# x = ConvLSTM2D(filters=num_filters, kernel_size=kernel_size, padding='same', return_sequences=False)(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Activation('relu')(x)\n",
    "\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# dense_1 = Dense(256, activation='relu')(x)\n",
    "# dropout_1 = Dropout(0.5)(dense_1)\n",
    "# dense_2 = Dense(128, activation='relu')(dropout_1)\n",
    "# dropout_2 = Dropout(0.5)(dense_2)\n",
    "# dense_3 = Dense(num_classes)(dropout_2)          \n",
    "# softmax = Softmax(name='softmax')(dense_3)\n",
    "\n",
    "# optimizer = Adam(learning_rate=0.00050)\n",
    "# model = Model(rf_input, softmax)\n",
    "# model.compile(loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "\n",
    "# print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predict = model.predict(X_test[0:1])\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 2   # number of epochs to train on\n",
    "batch_size = 1024  # training batch size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Callback\n",
    "checkpoint_dir = 'resnet_checkpoints'\n",
    "#os.mkdir(checkpoint_dir)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath =checkpoint_dir + '/best_checkpoint.h5', \n",
    "                                         \n",
    "                                                 verbose = 1,\n",
    "                                                 save_best_only=True, \n",
    "                                                 save_weights_only=False,\n",
    "                                                 mode='auto')\n",
    "earlystopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor = 'val_loss',\n",
    "        patience = 5,\n",
    "        mode='auto',\n",
    "        verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        # return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "        return int(np.ceil(X_train.shape[0] / float(self.batch_size)))\n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = DataGenerator(X_train, Y_train, 1024)\n",
    "test_gen = DataGenerator(X_test, Y_test, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_gen,\n",
    "    batch_size=batch_size,\n",
    "    epochs=nb_epoch,\n",
    "    verbose=1,\n",
    "    validation_data=test_gen,\n",
    "    callbacks = [ cp_callback,earlystopping_callback]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR CLDNN MODEL\n",
    "# history = model.fit(X_train[-30000:0],\n",
    "#     Y_train[-30000:0],\n",
    "#     batch_size=128,\n",
    "#     epochs=nb_epoch,\n",
    "#     verbose=1,\n",
    "#     validation_data=(X_test, Y_test),\n",
    "#     callbacks = [ cp_callback,earlystopping_callback]\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_checkpoint = checkpoint_dir + '/best_checkpoint.h5'\n",
    "model.load_weights(best_checkpoint)\n",
    "!mkdir -p fp_model\n",
    "model.save ('fp_model/resnet_fp_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show simple version of performance\n",
    "score = model.evaluate(X_test, Y_test,  verbose=0, batch_size=batch_size)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues, labels=[]):\n",
    "    plt.figure(figsize = (15,10))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    label_len = np.shape(labels)[0]\n",
    "    tick_marks = np.arange(label_len)\n",
    "    plt.xticks(tick_marks, labels, rotation=45)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "    plt.tight_layout()    \n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "test_Y_hat = model.predict(X_test, batch_size=batch_size)\n",
    "conf = np.zeros([num_classes,num_classes])\n",
    "confnorm = np.zeros([num_classes,num_classes])\n",
    "for i in range(0,X_test.shape[0]):\n",
    "    j = list(Y_test[i,:]).index(1)\n",
    "    k = int(np.argmax(test_Y_hat[i,:]))\n",
    "    conf[j,k] = conf[j,k] + 1\n",
    "for i in range(0,num_classes):\n",
    "    confnorm[i,:] = conf[i,:] / np.sum(conf[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confnorm, labels=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test,batch_size=batch_size)\n",
    "y_pred = np.argmax(Y_pred, axis = 1)\n",
    "y_actual = np.argmax(Y_test, axis = 1)\n",
    "classificationreport_fp = classification_report(y_actual,y_pred, target_names=mods)\n",
    "print(classificationreport_fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 128\n",
    "progress = ProgressBar()\n",
    "snrlist = np.unique(Z_test)\n",
    "acc_snr_arr = []\n",
    "\n",
    "# interate over SNRs\n",
    "for snr in progress(snrlist):\n",
    "    acc_arr = []\n",
    "    i_SNR = np.where(Z_test==snr)\n",
    "    X_SNR = X_test[i_SNR[0],:,:]\n",
    "    Y_SNR = Y_test[i_SNR[0],:]\n",
    "    X_SNR_len = np.shape(X_SNR)[0]\n",
    "    total_batches = int(X_SNR_len/batchsize)\n",
    "    \n",
    "    for i in (range(0, total_batches)):\n",
    "        x_batch, y_batch = X_SNR[i*batchsize:i*batchsize+batchsize], Y_SNR[i*batchsize:i*batchsize+batchsize]\n",
    "        \n",
    "        # model prediction\n",
    "        pred = model.predict(x_batch)\n",
    "        \n",
    "        #Pediction values are onehote, corresponding to indices representing different modulation types\n",
    "        pred_ind = np.argmax(pred, axis=1)\n",
    "        expected_ind = np.argmax(y_batch, axis=1)\n",
    "        matches  = sum(np.equal(pred_ind, expected_ind))\n",
    "        acc      = matches/batchsize\n",
    "        acc_arr.append(acc)\n",
    "\n",
    "    # Average the per-batch accuracy values\n",
    "    accuracy = np.mean(acc_arr)\n",
    "    acc_snr_arr.append(accuracy)\n",
    "    print(\"SNR: \", snr, \"accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(1,1))\n",
    "plt.show()\n",
    "fig= plt.figure(figsize=(10,8))\n",
    "plt.plot(snrlist, acc_snr_arr, 'bo-', label='accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('SNR')\n",
    "plt.title(\"Accuracy vs, SNR for Floating Point Model\")\n",
    "plt.legend()\n",
    "plt.axis([-22, 32, 0, 1.0])\n",
    "plt.grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e9f4aaaf30324fd950bc82eb6f1e586e6dd5534d96f242227cbe8027d9aab63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
